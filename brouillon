# from flask import Flask, jsonify, request, render_template
from flask import Flask, jsonify
import joblib
import pandas as pd
import numpy as np
import json
import matplotlib.pyplot as plt
import streamlit as st
import os
import time
import shap
import pickle

app = Flask(__name__)
current_folder = os.getcwd()
basepath = os.path.join(current_folder, "Models")

# load models, threshold, data and explainer
model_load = joblib.load(os.path.join(basepath, "model.pkl"))
best_thresh = joblib.load(os.path.join(basepath, "best_thresh_LightGBM_NS.pkl"))
X_test = pd.read_csv(os.path.join(basepath, "X_test_sample.csv"), index_col=0)
y_test = pd.read_csv(os.path.join(basepath, "y_test_sample.csv"), index_col=0)
#shap_values = pd.read_csv(os.path.join(basepath, "shap_values_sample_.csv"), index_col=0)
shap_values1 = pd.read_csv(os.path.join(basepath, "shap_values1_sample.csv"), index_col=0)
# Charger l'objet shap_values
#with open(os.path.join(basepath, "_shap_values_sample_.pkl"), "rb") as f:
#    _shap_values_= pickle.load(f)
_shap_values_=joblib.load(os.path.join(basepath, "_shap_values_sample_.pkl"))

                              
# Liste des clients à supprimer (pb d'accès)--> client_ID non trouvé
clients_a_supprimer = [136718, 307488, 378985]

data = pd.DataFrame(y_test, index=y_test.index)#.reset_index() #à supprimer si necessaire (index)
# Supprimer les clients
data = data[~data['SK_ID_CURR'].isin(clients_a_supprimer)]
# Optionnel : sauvegarder les données filtrées
data.to_csv(os.path.join(basepath, "y_test_filtered.csv"), index=False)
columns = joblib.load('Models/columns.pkl')                                
# Compute feature importance
# compute mean of absolute values for shap values
vals = np.abs(shap_values1).mean(0)
# compute feature importance as a dataframe containing vals
feature_importance = pd.DataFrame(list(zip(columns, vals)),\
    columns=['col_name','feature_importance_vals'])
# Define top 10 features for customer details
top_10 = feature_importance.sort_values(by='feature_importance_vals', ascending=False)[0:10].col_name.tolist()
# Define top 20 features for comparison vs group
top_20 = feature_importance.sort_values(by='feature_importance_vals', ascending=False)[0:20].col_name.tolist()
feat_tot = feature_importance.feature_importance_vals.sum()
feat_top = feature_importance.loc[feature_importance['col_name'].isin(top_20)].feature_importance_vals.sum()

print(X_test.shape)
print(y_test.shape)

print(type(_shap_values_))
# Vérifiez la longueur de la liste et le type des éléments
print(f"Nombre d'éléments dans la liste : {len(_shap_values_)}")
print(f"Type du premier élément : {type(_shap_values_[0])}")
# Accéder à l'élément qui contient 'base_values'
# Choisissez un index valide, par exemple, 0 pour le premier élément
index = 0  # Remplacez par l'index souhaité

# Vérifiez que l'index est valide
if index < len(_shap_values_):
    element = _shap_values_[index]
    
    # Assurez-vous que cet élément a l'attribut 'base_values'
    if hasattr(element, 'base_values'):
        # Accéder à base_values
        base_values = element.base_values  # Vous pouvez également ajouter des indices ici si nécessaire
        print(base_values)
    else:
        print("L'élément n'a pas l'attribut 'base_values'")
else:
    print("Index hors limites.")

print(_shap_values_.base_values[data]) 


